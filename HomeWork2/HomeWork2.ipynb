{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "mycorpus = PlaintextCorpusReader('.', '.*\\.txt')\n",
    "type(mycorpus.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4016"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_docs = len(mycorpus.fileids())  # mycorpus.fileids() gives the list of all the files\n",
    "num_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the contents of all the files in the file_contents array\n",
    "file_ids = mycorpus.fileids()\n",
    "file_contents = []  # file_contents is the array of all the file contents\n",
    "for i in range(len(file_ids)):\n",
    "    file = file_ids[i]\n",
    "    file_handle = open(file,'r',encoding = \"ISO-8859-1\")\n",
    "    file_content = file_handle.read()\n",
    "    # file content has the actual content of each of the file\n",
    "    file_contents.append(file_content)\n",
    "    file_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4016\n",
      "Title       : CRB: Genetic Diversity of Endangered Populations of Mysticete Whales:\n",
      "               Mitochondrial DNA and Historical Demography\n",
      "Type        : Award\n",
      "NSF Org     : DEB \n",
      "Latest\n",
      "Amendment\n",
      "Date        : August 1,  1991     \n",
      "File        : a9000006\n",
      "\n",
      "Award Number: 9000006\n",
      "Award Instr.: Continuing grant                             \n",
      "Prgm Manager: Scott Collins                           \n",
      "\t      DEB  DIVISION OF ENVIRONMENTAL BIOLOGY       \n",
      "\t      BIO  DIRECT FOR BIOLOGICAL SCIENCES          \n",
      "Start Date  : June 1,  1990       \n",
      "Expires     : November 30,  1992   (Estimated)\n",
      "Expected\n",
      "Total Amt.  : $179720             (Estimated)\n",
      "Investigator: Stephen R. Palumbi   (Principal Investigator current)\n",
      "Sponsor     : U of Hawaii Manoa\n",
      "\t      2530 Dole Street\n",
      "\t      Honolulu, HI  968222225    808/956-7800\n",
      "\n",
      "NSF Program : 1127      SYSTEMATIC & POPULATION BIOLO\n",
      "Fld Applictn: 0000099   Other Applications NEC                  \n",
      "              61        Life Science Biological                 \n",
      "Program Ref : 9285,\n",
      "Abstract    :\n",
      "                                                                                             \n",
      "              Commercial exploitation over the past two hundred years drove                  \n",
      "              the great Mysticete whales to near extinction.  Variation in                   \n",
      "              the sizes of populations prior to exploitation, minimal                        \n",
      "              population size during exploitation and current population                     \n",
      "              sizes permit analyses of the effects of differing levels of                    \n",
      "              exploitation on species with different biogeographical                         \n",
      "              distributions and life-history characteristics.  Dr. Stephen                   \n",
      "              Palumbi at the University of Hawaii will study the genetic                     \n",
      "              population structure of three whale species in this context,                   \n",
      "              the Humpback Whale, the Gray Whale and the Bowhead Whale.  The                 \n",
      "              effect of demographic history will be determined by comparing                  \n",
      "              the genetic structure of the three species.  Additional studies                \n",
      "              will be carried out on the Humpback Whale.  The humpback has a                 \n",
      "              world-wide distribution, but the Atlantic and Pacific                          \n",
      "              populations of the northern hemisphere appear to be discrete                   \n",
      "              populations, as is the population of the southern hemispheric                  \n",
      "              oceans.  Each of these oceanic populations may be further                      \n",
      "              subdivided into smaller isolates, each with its own migratory                  \n",
      "              pattern and somewhat distinct gene pool.  This study will                      \n",
      "              provide information on the level of genetic isolation among                    \n",
      "              populations and the levels of gene flow and genealogical                       \n",
      "              relationships among populations.  This detailed genetic                        \n",
      "              information will facilitate international policy decisions                     \n",
      "              regarding the conservation and management of these magnificent                 \n",
      "              mammals.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(file_contents))\n",
    "print(file_contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets use regex pattern matching to find out the\n",
    "# required data \n",
    "\n",
    "# creating the result file to store the results of part 2\n",
    "# resultfile = open('result.txt', 'w')\n",
    "# resultfile.write('Komal')\n",
    "# resultfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a9000045']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample demo of pattern matching\n",
    "import re\n",
    "shorttext = file_contents[5]\n",
    "\n",
    "pword = re.compile('File *: *(\\w+)')\n",
    "re.findall(pword, shorttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CCR']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pword = re.compile('NSF Org *: *(\\w+)')\n",
    "re.findall(pword, shorttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53277"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pword = re.compile('Total Amt\\. *: *([$]\\d+)')\n",
    "re.findall(pword, shorttext)\n",
    "\n",
    "pword = re.compile('Total Amt\\. *: *[$](\\d+)')\n",
    "res = re.findall(pword, shorttext)\n",
    "type(res[0])\n",
    "int(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Flags not at the start of the expression 'Abstract *: *\\n[ \\t]*(' (truncated)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pword = re.compile('Abstract *: *\\n[ \\t]*((?s).*)')\n",
    "# text contains the \n",
    "text = re.findall(pword, shorttext)\n",
    "# print(text)\n",
    "\n",
    "type(text[0])\n",
    "text[0]\n",
    "\n",
    "# remove \\n from the string\n",
    "newtext = text[0].replace('\\n','')\n",
    "#print(newtext)\n",
    "\n",
    "# remove multiple white spaces from the string\n",
    "final_text = ' '.join(newtext.split())\n",
    "#print(type(final_text))\n",
    "\n",
    "# identify sentences in the abstract, you can use sentence tokenizer in Python\n",
    "sent_tokenize_list = sent_tokenize(final_text)\n",
    "len(sent_tokenize_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grants_amount is a list of all the grants\n",
    "grant_amounts = []\n",
    "# this information is used to get the organization granting the max grant\n",
    "organization_giving_max_grant = ''\n",
    "\n",
    "resultfile = open('result1.txt', 'w+')\n",
    "for i in range(0,len(file_contents)-1):\n",
    "    shorttext = file_contents[i]\n",
    "\n",
    "    # extract the file text\n",
    "    pword = re.compile('File *: *(\\w+)')\n",
    "    file_field = re.findall(pword, shorttext)\n",
    "    resultfile.write(file_field[0])\n",
    "    \n",
    "    resultfile.write('\\t')\n",
    "    pword = re.compile('NSF Org *: *(\\w+)')\n",
    "    nsf_field = re.findall(pword, shorttext)\n",
    "    resultfile.write(nsf_field[0])\n",
    "    \n",
    "    resultfile.write(' ')\n",
    "    pword = re.compile('Total Amt\\. *: *([$]\\d+)')\n",
    "    amount_field = re.findall(pword, shorttext)\n",
    "    resultfile.write(amount_field[0])\n",
    "    \n",
    "    \n",
    "    # getting the amount in $ to find out the maximum grant amount \n",
    "    # from all the awards (I used this information to describe the text)\n",
    "    # in question 2A.\n",
    "    pword = re.compile('Total Amt\\. *: *[$](\\d+)')\n",
    "    res = re. findall(pword, shorttext)\n",
    "    grant_amounts.append(int(res[0]))\n",
    "    if (int(res[0]) == 18806079):\n",
    "        organization_giving_max_grant = nsf_field[0]\n",
    "    \n",
    "    resultfile.write(' ')\n",
    "    pword = re.compile('Abstract *: *\\n[ \\t]*((?s).*)')\n",
    "    # text contains string with extra white spaces and \\n characters\n",
    "    text = re.findall(pword, shorttext)\n",
    "    newtext = text[0].replace('\\n','')\n",
    "    abstract_field = ' '.join(newtext.split())\n",
    "    resultfile.write(abstract_field)\n",
    "    resultfile.write('\\n')\n",
    "resultfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_abstract and max_abstract len is used to find the max len of the abstract \n",
    "# in the given data set\n",
    "min_abstract_len = 99999\n",
    "max_abstract_len = 0\n",
    "\n",
    "resultfile = open('result2.txt', 'w+')\n",
    "resultfile.write('Abstract_ID | Sentence_No | Sentence\\n')\n",
    "resultfile.write('--------------------------------------\\n')\n",
    "for i in range(0,len(file_contents)-1):\n",
    "    shorttext = file_contents[i]\n",
    "\n",
    "    # extract the file text\n",
    "    pword = re.compile('File *: *(\\w+)')\n",
    "    file_field = re.findall(pword, shorttext)    \n",
    "    \n",
    "    pword = re.compile('Abstract *: *\\n[ \\t]*((?s).*)')\n",
    "    # text contains string with extra white spaces and \\n characters\n",
    "    text = re.findall(pword, shorttext)\n",
    "    newtext = text[0].replace('\\n','')\n",
    "    abstract_field = ' '.join(newtext.split())\n",
    "\n",
    "    sent_tokenize_list = sent_tokenize(abstract_field)\n",
    "\n",
    "    for i in range (len(sent_tokenize_list)):\n",
    "        resultfile.write(file_field[0])\n",
    "        resultfile.write('|')\n",
    "        resultfile.write(str(i+1))\n",
    "        resultfile.write('|')\n",
    "        resultfile.write(sent_tokenize_list[i])\n",
    "        resultfile.write('\\n')\n",
    "    last_line = 'Number of sentences : ' + str(len(sent_tokenize_list)) + '\\n'    \n",
    "    max_abstract_len = max(max_abstract_len,len(sent_tokenize_list))\n",
    "    min_abstract_len = min(min_abstract_len, len(sent_tokenize_list))\n",
    "    resultfile.write(last_line)\n",
    "\n",
    "resultfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max grant amount : 18806079\n",
      "min grant amount : 0\n",
      "organizarion giving max grant : OCE\n",
      "max abstract length : 26\n",
      "min abstract length : 1\n"
     ]
    }
   ],
   "source": [
    "print('max grant amount : '+ str(max(grant_amounts)))\n",
    "print('min grant amount : '+ str(min(grant_amounts)))\n",
    "print('organizarion giving max grant : ' + organization_giving_max_grant)\n",
    "print('max abstract length : ' + str(max_abstract_len))\n",
    "print('min abstract length : ' + str(min_abstract_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
