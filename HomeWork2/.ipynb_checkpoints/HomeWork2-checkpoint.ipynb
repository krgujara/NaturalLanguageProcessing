{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "mycorpus = PlaintextCorpusReader('.', '.*\\.txt')\n",
    "type(mycorpus.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4016"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_docs = len(mycorpus.fileids())  # mycorpus.fileids() gives the list of all the files\n",
    "num_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the contents of all the files in the file_contents array\n",
    "file_ids = mycorpus.fileids()\n",
    "file_contents = []  # file_contents is the array of all the file contents\n",
    "for i in range(len(file_ids)):\n",
    "    file = file_ids[i]\n",
    "    file_handle = open(file,'r',encoding = \"ISO-8859-1\")\n",
    "    file_content = file_handle.read()\n",
    "    # file content has the actual content of each of the file\n",
    "    file_contents.append(file_content)\n",
    "    file_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4016\n",
      "Title       : Computational Complexity Theory and Circuit Complexity\n",
      "Type        : Award\n",
      "NSF Org     : CCR \n",
      "Latest\n",
      "Amendment\n",
      "Date        : May 21,  1990       \n",
      "File        : a9000045\n",
      "\n",
      "Award Number: 9000045\n",
      "Award Instr.: Standard Grant                               \n",
      "Prgm Manager: Krishna M. Kavi                         \n",
      "\t      CCR  DIV OF COMPUTER-COMMUNICATIONS RESEARCH \n",
      "\t      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR\n",
      "Start Date  : June 1,  1990       \n",
      "Expires     : November 30,  1992   (Estimated)\n",
      "Expected\n",
      "Total Amt.  : $53277              (Estimated)\n",
      "Investigator: Eric W. Allender Allender@cs.rutgers.edu  (Principal Investigator current)\n",
      "Sponsor     : Rutgers Univ New Brunswick\n",
      "\t      ASB III, 3 Rutgers Plaza\n",
      "\t      New Brunswick, NJ  08901    732/932-0150\n",
      "\n",
      "NSF Program : 2860      THEORY OF COMPUTING\n",
      "Fld Applictn: 0000099   Other Applications NEC                  \n",
      "              31        Computer Science & Engineering          \n",
      "Program Ref : \n",
      "Abstract    :\n",
      "              This research will study the complexity of computation using the               \n",
      "              framework of Boolean circuit complexity.  Special emphasis is placed           \n",
      "              on the following topics:                                                       \n",
      "                                                                                             \n",
      "              Strong separations of circuit classes: If known separations of small           \n",
      "              circuit complexity classes could be strengthened, it would imply               \n",
      "              separations on larger time- and space-complexity classes.  This                \n",
      "              connection will be investigated, using the notion of \"immunity\" as a           \n",
      "              tool.                                                                          \n",
      "                                                                                             \n",
      "              Width-bounded reducibility: This notion will be used as a tool to              \n",
      "              investigate the relationships among \"similar\" complexity classes.              \n",
      "                                                                                             \n",
      "              This project also investigates threshold circuits, an structure of the         \n",
      "              complexity class P/poly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(file_contents))\n",
    "print(file_contents[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets use regex pattern matching to find out the\n",
    "# required data \n",
    "\n",
    "# creating the result file to store the results of part 2\n",
    "# resultfile = open('result.txt', 'w')\n",
    "# resultfile.write('Komal')\n",
    "# resultfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a9000031']"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample demo of pattern matching\n",
    "import re\n",
    "shorttext = file_contents[1]\n",
    "\n",
    "pword = re.compile('File *: *(\\w+)')\n",
    "re.findall(pword, shorttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MCB']"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pword = re.compile('NSF Org *: *(\\w+)')\n",
    "re.findall(pword, shorttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90063"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pword = re.compile('Total Amt\\. *: *([$]\\d+)')\n",
    "re.findall(pword, shorttext)\n",
    "\n",
    "pword = re.compile('Total Amt\\. *: *[$](\\d+)')\n",
    "res = re.findall(pword, shorttext)\n",
    "type(res[0])\n",
    "int(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pword = re.compile('Abstract *: *\\n[ \\t]*((?s).*)')\n",
    "# text contains the \n",
    "text = re.findall(pword, shorttext)\n",
    "# print(text)\n",
    "\n",
    "type(text[0])\n",
    "text[0]\n",
    "\n",
    "# remove \\n from the string\n",
    "newtext = text[0].replace('\\n','')\n",
    "#print(newtext)\n",
    "\n",
    "# remove multiple white spaces from the string\n",
    "final_text = ' '.join(newtext.split())\n",
    "#print(type(final_text))\n",
    "\n",
    "# identify sentences in the abstract, you can use sentence tokenizer in Python\n",
    "sent_tokenize_list = sent_tokenize(final_text)\n",
    "len(sent_tokenize_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grants_amount is a list of all the grants\n",
    "grant_amounts = []\n",
    "\n",
    "resultfile = open('result1.txt', 'w+')\n",
    "for i in range(0,len(file_contents)-1):\n",
    "    shorttext = file_contents[i]\n",
    "\n",
    "    # extract the file text\n",
    "    pword = re.compile('File *: *(\\w+)')\n",
    "    file_field = re.findall(pword, shorttext)\n",
    "    resultfile.write(file_field[0])\n",
    "    \n",
    "    resultfile.write('\\t')\n",
    "    pword = re.compile('NSF Org *: *(\\w+)')\n",
    "    nsf_field = re.findall(pword, shorttext)\n",
    "    resultfile.write(nsf_field[0])\n",
    "    \n",
    "    resultfile.write(' ')\n",
    "    pword = re.compile('Total Amt\\. *: *([$]\\d+)')\n",
    "    amount_field = re.findall(pword, shorttext)\n",
    "    resultfile.write(amount_field[0])\n",
    "    \n",
    "    \n",
    "    # getting the amount in $ to find out the maximum grant amount from all the awards\n",
    "    pword = re.compile('Total Amt\\. *: *[$](\\d+)')\n",
    "    res = re. findall(pword, shorttext)\n",
    "    grant_amounts.append(int(res[0]))\n",
    "    \n",
    "    resultfile.write(' ')\n",
    "    pword = re.compile('Abstract *: *\\n[ \\t]*((?s).*)')\n",
    "    # text contains string with extra white spaces and \\n characters\n",
    "    text = re.findall(pword, shorttext)\n",
    "    newtext = text[0].replace('\\n','')\n",
    "    abstract_field = ' '.join(newtext.split())\n",
    "    resultfile.write(abstract_field)\n",
    "\n",
    "    resultfile.write('\\n')\n",
    "\n",
    "resultfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultfile = open('result2.txt', 'w+')\n",
    "resultfile.write('Abstract_ID | Sentence_No | Sentence\\n')\n",
    "resultfile.write('--------------------------------------\\n')\n",
    "for i in range(0,len(file_contents)-1):\n",
    "    shorttext = file_contents[i]\n",
    "\n",
    "    # extract the file text\n",
    "    pword = re.compile('File *: *(\\w+)')\n",
    "    file_field = re.findall(pword, shorttext)    \n",
    "    \n",
    "    pword = re.compile('Abstract *: *\\n[ \\t]*((?s).*)')\n",
    "    # text contains string with extra white spaces and \\n characters\n",
    "    text = re.findall(pword, shorttext)\n",
    "    newtext = text[0].replace('\\n','')\n",
    "    abstract_field = ' '.join(newtext.split())\n",
    "\n",
    "    sent_tokenize_list = sent_tokenize(abstract_field)\n",
    "\n",
    "    for i in range (len(sent_tokenize_list)):\n",
    "        resultfile.write(file_field[0])\n",
    "        resultfile.write('|')\n",
    "        resultfile.write(str(i+1))\n",
    "        resultfile.write('|')\n",
    "        resultfile.write(sent_tokenize_list[i])\n",
    "        resultfile.write('\\n')\n",
    "    last_line = 'Number of sentences : ' + str(len(sent_tokenize_list)) + '\\n'    \n",
    "    resultfile.write(last_line)\n",
    "\n",
    "resultfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
