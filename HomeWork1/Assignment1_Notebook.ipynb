{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycorpus = PlaintextCorpusReader('.','.*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_union_part1.txt', 'state_union_part2.txt', 'state_union_policy.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycorpus.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " part1 = mycorpus.fileids()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'state_union_part1.txt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1string = mycorpus.raw('state_union_part1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " part1tokens = nltk.word_tokenize(part1string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Complete',\n",
       " 'State',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Union',\n",
       " 'Addresses',\n",
       " ',',\n",
       " 'from',\n",
       " '1790',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Present',\n",
       " '(',\n",
       " '#',\n",
       " '41',\n",
       " 'in',\n",
       " 'our',\n",
       " 'series',\n",
       " 'of',\n",
       " 'US',\n",
       " 'Presidential',\n",
       " 'State',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Union',\n",
       " 'Addresses',\n",
       " ')',\n",
       " 'Copyright',\n",
       " 'laws',\n",
       " 'are',\n",
       " 'changing',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'Be',\n",
       " 'sure',\n",
       " 'to',\n",
       " 'check',\n",
       " 'the',\n",
       " 'copyright',\n",
       " 'laws',\n",
       " 'for',\n",
       " 'your',\n",
       " 'country',\n",
       " 'before',\n",
       " 'downloading',\n",
       " 'or',\n",
       " 'redistributing',\n",
       " 'this',\n",
       " 'or',\n",
       " 'any',\n",
       " 'other',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'eBook',\n",
       " '.',\n",
       " 'This',\n",
       " 'header',\n",
       " 'should',\n",
       " 'be',\n",
       " 'the',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'seen',\n",
       " 'when',\n",
       " 'viewing',\n",
       " 'this',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'file',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'not',\n",
       " 'remove',\n",
       " 'it',\n",
       " '.',\n",
       " 'Do',\n",
       " 'not',\n",
       " 'change',\n",
       " 'or',\n",
       " 'edit',\n",
       " 'the',\n",
       " 'header',\n",
       " 'without',\n",
       " 'written',\n",
       " 'permission',\n",
       " '.',\n",
       " 'Please',\n",
       " 'read',\n",
       " 'the',\n",
       " '``',\n",
       " 'legal']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1tokens[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3137736"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(part1string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557939"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(part1tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphapart1 = [w for w in part1tokens if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Complete',\n",
       " 'State',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Union',\n",
       " 'Addresses',\n",
       " 'from',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Present',\n",
       " 'in',\n",
       " 'our',\n",
       " 'series',\n",
       " 'of',\n",
       " 'US',\n",
       " 'Presidential',\n",
       " 'State',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Union',\n",
       " 'Addresses',\n",
       " 'Copyright',\n",
       " 'laws',\n",
       " 'are',\n",
       " 'changing',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'world',\n",
       " 'Be',\n",
       " 'sure',\n",
       " 'to',\n",
       " 'check',\n",
       " 'the',\n",
       " 'copyright',\n",
       " 'laws',\n",
       " 'for',\n",
       " 'your',\n",
       " 'country',\n",
       " 'before',\n",
       " 'downloading',\n",
       " 'or',\n",
       " 'redistributing',\n",
       " 'this',\n",
       " 'or',\n",
       " 'any',\n",
       " 'other',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'eBook',\n",
       " 'This',\n",
       " 'header',\n",
       " 'should',\n",
       " 'be',\n",
       " 'the',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'seen',\n",
       " 'when',\n",
       " 'viewing',\n",
       " 'this',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'file',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'not',\n",
       " 'remove',\n",
       " 'it',\n",
       " 'Do',\n",
       " 'not',\n",
       " 'change',\n",
       " 'or',\n",
       " 'edit',\n",
       " 'the',\n",
       " 'header',\n",
       " 'without',\n",
       " 'written',\n",
       " 'permission',\n",
       " 'Please',\n",
       " 'read',\n",
       " 'the',\n",
       " 'legal',\n",
       " 'small',\n",
       " 'print',\n",
       " 'and',\n",
       " 'other',\n",
       " 'information',\n",
       " 'about',\n",
       " 'the',\n",
       " 'eBook',\n",
       " 'and',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'at']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " alphapart1[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphalowerpart1 = [w.lower( ) for w in alphapart1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'of',\n",
       " 'complete',\n",
       " 'state',\n",
       " 'of',\n",
       " 'the',\n",
       " 'union',\n",
       " 'addresses',\n",
       " 'from',\n",
       " 'to',\n",
       " 'the',\n",
       " 'present',\n",
       " 'in',\n",
       " 'our',\n",
       " 'series',\n",
       " 'of',\n",
       " 'us',\n",
       " 'presidential',\n",
       " 'state',\n",
       " 'of',\n",
       " 'the',\n",
       " 'union',\n",
       " 'addresses',\n",
       " 'copyright',\n",
       " 'laws',\n",
       " 'are',\n",
       " 'changing',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'world',\n",
       " 'be',\n",
       " 'sure',\n",
       " 'to',\n",
       " 'check',\n",
       " 'the',\n",
       " 'copyright',\n",
       " 'laws',\n",
       " 'for',\n",
       " 'your',\n",
       " 'country',\n",
       " 'before',\n",
       " 'downloading',\n",
       " 'or',\n",
       " 'redistributing',\n",
       " 'this',\n",
       " 'or']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphalowerpart1[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "len(stopwords)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoppedalphalowerpart1 = [w for w in alphalowerpart1 if w not in stopwords]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist(stoppedalphalowerpart1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdistkeys = list(fdist.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'complete',\n",
       " 'state',\n",
       " 'union',\n",
       " 'addresses',\n",
       " 'present',\n",
       " 'series',\n",
       " 'us',\n",
       " 'presidential',\n",
       " 'copyright',\n",
       " 'laws',\n",
       " 'changing',\n",
       " 'world',\n",
       " 'sure',\n",
       " 'check',\n",
       " 'country',\n",
       " 'downloading',\n",
       " 'redistributing',\n",
       " 'header',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'seen',\n",
       " 'viewing',\n",
       " 'file',\n",
       " 'please',\n",
       " 'remove',\n",
       " 'change',\n",
       " 'edit',\n",
       " 'without',\n",
       " 'written',\n",
       " 'permission',\n",
       " 'read',\n",
       " 'legal',\n",
       " 'small',\n",
       " 'print',\n",
       " 'information',\n",
       " 'bottom',\n",
       " 'included',\n",
       " 'important',\n",
       " 'specific',\n",
       " 'rights',\n",
       " 'restrictions',\n",
       " 'may',\n",
       " 'used',\n",
       " 'also',\n",
       " 'find',\n",
       " 'make',\n",
       " 'donation']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdistkeys[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "topkeys = fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('states', 2725)\n",
      "('government', 2220)\n",
      "('united', 1864)\n",
      "('may', 1562)\n",
      "('congress', 1500)\n",
      "('upon', 1455)\n",
      "('would', 1381)\n",
      "('public', 1375)\n",
      "('country', 1163)\n",
      "('great', 1073)\n",
      "('made', 1061)\n",
      "('state', 1045)\n",
      "('last', 911)\n",
      "('war', 834)\n",
      "('present', 812)\n",
      "('time', 808)\n",
      "('people', 786)\n",
      "('year', 785)\n",
      "('power', 744)\n",
      "('citizens', 723)\n",
      "('subject', 711)\n",
      "('shall', 694)\n",
      "('without', 663)\n",
      "('union', 643)\n",
      "('act', 627)\n",
      "('treaty', 624)\n",
      "('one', 620)\n",
      "('part', 618)\n",
      "('mexico', 605)\n",
      "('general', 601)\n",
      "('every', 590)\n",
      "('treasury', 590)\n",
      "('necessary', 575)\n",
      "('constitution', 557)\n",
      "('new', 548)\n",
      "('duty', 529)\n",
      "('foreign', 519)\n",
      "('two', 510)\n",
      "('commerce', 506)\n",
      "('nations', 502)\n",
      "('peace', 501)\n",
      "('system', 494)\n",
      "('laws', 492)\n",
      "('duties', 488)\n",
      "('within', 479)\n",
      "('law', 477)\n",
      "('us', 463)\n",
      "('interests', 451)\n",
      "('interest', 444)\n",
      "('amount', 443)\n"
     ]
    }
   ],
   "source": [
    "for pair in topkeys:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Freq Dist\n",
    "Another way to look for interesting characterizations of a corpus is to look at pairs of words that are frequently collocated, that is, they occur in a sequence called a bigram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We start by making an object called a BigramCollocationFinder.  The finder then allows us to call other functions to filter the bigrams that it collected and to give scores to the bigrams.  As a first step, we can score the bigrams by frequency.  Be sure to use the original tokens from the document and not the filtered tokens that you might create to look at word frequencies. For example, the bigrams of the sentence “run after the fox!”  include “run after”, “after the”, and “the fox”. If you use the original tokens you will obtain these bigrams. If you filter the sentence with the stop words list, then you may not have “the” after the filtering. Then your bigrams will have “after fox” – which is not a bigram in the original dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(alphalowerpart1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('of', 'the'), 0.023139252704378124)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scored)\n",
    "first = scored[0]\n",
    "type(first)\n",
    "first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the'), 0.023139252704378124)\n",
      "(('to', 'the'), 0.007783594908345917)\n",
      "(('in', 'the'), 0.006009076290590155)\n",
      "(('by', 'the'), 0.00399560483468185)\n",
      "(('for', 'the'), 0.0036783068036924087)\n",
      "(('united', 'states'), 0.0035686235337207503)\n",
      "(('the', 'united'), 0.003543161346048758)\n",
      "(('and', 'the'), 0.0033061671377171385)\n",
      "(('on', 'the'), 0.0032160701659547045)\n",
      "(('of', 'our'), 0.0030887592275947438)\n",
      "(('it', 'is'), 0.0028635167981886592)\n",
      "(('to', 'be'), 0.0028615581683677366)\n",
      "(('have', 'been'), 0.0026284812196779622)\n",
      "(('with', 'the'), 0.002505087540959846)\n",
      "(('that', 'the'), 0.002450245905974017)\n",
      "(('has', 'been'), 0.0024189078288392573)\n",
      "(('from', 'the'), 0.0021388237644473433)\n",
      "(('of', 'a'), 0.0019096640753994136)\n",
      "(('the', 'public'), 0.00179606354578591)\n",
      "(('will', 'be'), 0.001680504386351484)\n",
      "(('the', 'government'), 0.0016452490495748795)\n",
      "(('at', 'the'), 0.0015042277024684611)\n",
      "(('may', 'be'), 0.001306406090555291)\n",
      "(('of', 'congress'), 0.0012672334941368417)\n",
      "(('and', 'to'), 0.0012300195275393147)\n",
      "(('upon', 'the'), 0.001120336257567656)\n",
      "(('of', 'this'), 0.0011046672190002762)\n",
      "(('of', 'their'), 0.0011007499593584313)\n",
      "(('the', 'same'), 0.0011007499593584313)\n",
      "(('the', 'present'), 0.0010889981804328964)\n"
     ]
    }
   ],
   "source": [
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying filters now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before that, adding the 'united', 'states' in the list of stop words, because these words will definitely occur frequently in this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.append(\"united\")\n",
    "stopwords.append(\"states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('great', 'britain'), 0.0005366645709327583)\n",
      "(('last', 'session'), 0.00047398841666323907)\n",
      "(('public', 'debt'), 0.0003505947379451231)\n",
      "(('fiscal', 'year'), 0.00028204269421283645)\n",
      "(('union', 'address'), 0.00028204269421283645)\n",
      "(('public', 'lands'), 0.0002546218767199218)\n",
      "(('two', 'countries'), 0.000238952838152542)\n",
      "(('present', 'year'), 0.0002076147610177824)\n",
      "(('fellow', 'citizens'), 0.00018998709262948012)\n",
      "(('general', 'government'), 0.0001821525733457902)\n",
      "(('year', 'ending'), 0.0001821525733457902)\n",
      "(('british', 'government'), 0.00018019394352486773)\n",
      "(('two', 'governments'), 0.00017431805406210033)\n",
      "(('federal', 'government'), 0.00016648353477841042)\n",
      "(('annual', 'message'), 0.00015864901549472052)\n",
      "(('public', 'service'), 0.00015669038567379804)\n",
      "(('last', 'annual'), 0.00014689723656918565)\n",
      "(('public', 'money'), 0.00013514545764365082)\n",
      "(('indian', 'tribes'), 0.0001292695681808834)\n",
      "(('mexican', 'government'), 0.0001273109383599609)\n",
      "(('treasury', 'notes'), 0.0001273109383599609)\n",
      "(('commercial', 'intercourse'), 0.00012339367871811596)\n",
      "(('address', 'december'), 0.00010968326997165862)\n",
      "(('new', 'mexico'), 0.00010968326997165862)\n",
      "(('favorable', 'consideration'), 0.00010772464015073614)\n",
      "(('naval', 'force'), 0.00010772464015073614)\n",
      "(('central', 'america'), 9.989012086704625e-05)\n",
      "(('present', 'session'), 9.989012086704625e-05)\n",
      "(('french', 'government'), 9.793149104612377e-05)\n",
      "(('new', 'york'), 9.59728612252013e-05)\n",
      "(('friendly', 'relations'), 9.401423140427882e-05)\n",
      "(('ending', 'june'), 9.009697176243387e-05)\n",
      "(('existing', 'laws'), 8.813834194151139e-05)\n",
      "(('good', 'faith'), 8.813834194151139e-05)\n",
      "(('american', 'citizens'), 8.422108229966645e-05)\n",
      "(('foreign', 'nations'), 8.422108229966645e-05)\n",
      "(('taken', 'place'), 8.422108229966645e-05)\n",
      "(('last', 'year'), 8.226245247874397e-05)\n",
      "(('past', 'year'), 8.226245247874397e-05)\n",
      "(('september', 'last'), 8.226245247874397e-05)\n",
      "(('american', 'people'), 8.03038226578215e-05)\n",
      "(('military', 'force'), 8.03038226578215e-05)\n",
      "(('ensuing', 'year'), 7.834519283689902e-05)\n",
      "(('minister', 'plenipotentiary'), 7.834519283689902e-05)\n",
      "(('slave', 'trade'), 7.638656301597654e-05)\n",
      "(('spanish', 'government'), 7.638656301597654e-05)\n",
      "(('present', 'fiscal'), 7.246930337413159e-05)\n",
      "(('two', 'nations'), 7.246930337413159e-05)\n",
      "(('great', 'extent'), 6.855204373228664e-05)\n",
      "(('public', 'moneys'), 6.855204373228664e-05)\n"
     ]
    }
   ],
   "source": [
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def apply_ngram_filter(self, fn):\n",
    "        # \"Removes candidate ngrams (w1, w2, ...) where fn(w1, w2, ...) evaluates to True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('great', 'britain'), 0.0005366645709327583)\n",
      "(('last', 'session'), 0.00047398841666323907)\n",
      "(('public', 'debt'), 0.0003505947379451231)\n",
      "(('fiscal', 'year'), 0.00028204269421283645)\n",
      "(('union', 'address'), 0.00028204269421283645)\n",
      "(('public', 'lands'), 0.0002546218767199218)\n",
      "(('present', 'year'), 0.0002076147610177824)\n",
      "(('fellow', 'citizens'), 0.00018998709262948012)\n",
      "(('general', 'government'), 0.0001821525733457902)\n",
      "(('year', 'ending'), 0.0001821525733457902)\n",
      "(('british', 'government'), 0.00018019394352486773)\n",
      "(('federal', 'government'), 0.00016648353477841042)\n",
      "(('annual', 'message'), 0.00015864901549472052)\n",
      "(('public', 'service'), 0.00015669038567379804)\n",
      "(('last', 'annual'), 0.00014689723656918565)\n",
      "(('public', 'money'), 0.00013514545764365082)\n",
      "(('indian', 'tribes'), 0.0001292695681808834)\n",
      "(('mexican', 'government'), 0.0001273109383599609)\n",
      "(('treasury', 'notes'), 0.0001273109383599609)\n",
      "(('commercial', 'intercourse'), 0.00012339367871811596)\n",
      "(('address', 'december'), 0.00010968326997165862)\n",
      "(('favorable', 'consideration'), 0.00010772464015073614)\n",
      "(('naval', 'force'), 0.00010772464015073614)\n",
      "(('central', 'america'), 9.989012086704625e-05)\n",
      "(('present', 'session'), 9.989012086704625e-05)\n",
      "(('french', 'government'), 9.793149104612377e-05)\n",
      "(('friendly', 'relations'), 9.401423140427882e-05)\n",
      "(('ending', 'june'), 9.009697176243387e-05)\n",
      "(('existing', 'laws'), 8.813834194151139e-05)\n",
      "(('good', 'faith'), 8.813834194151139e-05)\n",
      "(('american', 'citizens'), 8.422108229966645e-05)\n",
      "(('foreign', 'nations'), 8.422108229966645e-05)\n",
      "(('taken', 'place'), 8.422108229966645e-05)\n",
      "(('last', 'year'), 8.226245247874397e-05)\n",
      "(('past', 'year'), 8.226245247874397e-05)\n",
      "(('september', 'last'), 8.226245247874397e-05)\n",
      "(('american', 'people'), 8.03038226578215e-05)\n",
      "(('military', 'force'), 8.03038226578215e-05)\n",
      "(('ensuing', 'year'), 7.834519283689902e-05)\n",
      "(('minister', 'plenipotentiary'), 7.834519283689902e-05)\n",
      "(('slave', 'trade'), 7.638656301597654e-05)\n",
      "(('spanish', 'government'), 7.638656301597654e-05)\n",
      "(('present', 'fiscal'), 7.246930337413159e-05)\n",
      "(('great', 'extent'), 6.855204373228664e-05)\n",
      "(('public', 'moneys'), 6.855204373228664e-05)\n",
      "(('government', 'would'), 6.659341391136417e-05)\n",
      "(('foreign', 'powers'), 6.46347840904417e-05)\n",
      "(('present', 'condition'), 6.46347840904417e-05)\n",
      "(('public', 'interest'), 6.46347840904417e-05)\n",
      "(('would', 'seem'), 6.46347840904417e-05)\n"
     ]
    }
   ],
   "source": [
    "finder.apply_ngram_filter(lambda w1, w2: len(w1) < 4)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information and other scores\n",
    "Recall that Mutual Information is a score introduced in the paper by Church and Hanks, where they defined it as an Association Ratio. Note that technically the original information theoretic definition of mutual information allows the two words to be in either order, but that the association ratio defined by Church and Hanks requires the words to be in order from left to right wherever they appear in the window\n",
    "\n",
    "In NLTK, the mutual information score is given by a function for Pointwise Mutual Information, where this is the version without the window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder2 = BigramCollocationFinder.from_words(stoppedalphalowerpart1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder2.apply_freq_filter(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('bona', 'fide'), 15.539910019165042)\n",
      "(('posse', 'comitatus'), 15.539910019165042)\n",
      "(('punta', 'arenas'), 15.539910019165042)\n",
      "(('ballot', 'box'), 15.276875613331246)\n",
      "(('del', 'norte'), 15.276875613331246)\n",
      "(('millard', 'fillmore'), 15.276875613331246)\n",
      "(('clayton', 'bulwer'), 14.861838114052404)\n",
      "(('guadalupe', 'hidalgo'), 14.691913112610091)\n",
      "(('porto', 'rico'), 14.691913112610091)\n",
      "(('writ', 'mandamus'), 14.598803708218608)\n",
      "(('franklin', 'pierce'), 14.539910019165042)\n",
      "(('la', 'plata'), 14.402406495415105)\n",
      "(('vera', 'cruz'), 14.276875613331246)\n",
      "(('entangling', 'alliances'), 14.206486285439848)\n",
      "(('seminaries', 'learning'), 14.013841207497453)\n",
      "(('gun', 'boats'), 13.884558190552486)\n",
      "(('nucleus', 'around'), 13.861838114052404)\n",
      "(('ruler', 'universe'), 13.861838114052404)\n",
      "(('costa', 'rica'), 13.8618381140524)\n",
      "(('santa', 'anna'), 13.774375272802065)\n",
      "(('santa', 'fe'), 13.774375272802065)\n",
      "(('van', 'buren'), 13.774375272802065)\n",
      "(('project', 'gutenberg'), 13.774375272802063)\n",
      "(('sublime', 'porte'), 13.732555097107436)\n",
      "(('tea', 'coffee'), 13.613910600608818)\n",
      "(('martin', 'van'), 13.604450271359752)\n",
      "(('ad', 'valorem'), 13.53991001916504)\n",
      "(('beacons', 'buoys'), 13.402406495415105)\n",
      "(('water', 'witch'), 13.402406495415105)\n",
      "(('quincy', 'adams'), 13.402406495415104)\n",
      "(('statute', 'book'), 13.338276157995391)\n",
      "(('buenos', 'ayres'), 13.276875613331244)\n",
      "(('indiana', 'illinois'), 13.139372089581311)\n",
      "(('de', 'facto'), 13.128483773438575)\n",
      "(('franking', 'privilege'), 13.106950611888934)\n",
      "(('rocky', 'mountains'), 13.054483191994798)\n",
      "(('andrew', 'jackson'), 12.972021031802825)\n",
      "(('retired', 'list'), 12.916979668244863)\n",
      "(('sooner', 'later'), 12.876945006442611)\n",
      "(('circulating', 'medium'), 12.81744399469395)\n",
      "(('intent', 'meaning'), 12.798828316526604)\n",
      "(('th', 'jefferson'), 12.774375272802065)\n",
      "(('john', 'quincy'), 12.774375272802063)\n",
      "(('precious', 'metals'), 12.715481583748494)\n",
      "(('thomas', 'jefferson'), 12.686912431551724)\n",
      "(('lake', 'erie'), 12.633019423556524)\n",
      "(('almighty', 'god'), 12.604450271359752)\n",
      "(('john', 'tyler'), 12.604450271359752)\n",
      "(('san', 'jacinto'), 12.576435895190155)\n",
      "(('san', 'juan'), 12.576435895190155)\n"
     ]
    }
   ],
   "source": [
    "scored = finder2.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
