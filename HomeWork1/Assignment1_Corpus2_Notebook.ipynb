{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycorpus = PlaintextCorpusReader('.','.*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_union_part1.txt', 'state_union_part2.txt', 'state_union_policy.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycorpus.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = mycorpus.fileids()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'state_union_part2.txt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1string = mycorpus.raw('state_union_part1.txt')\n",
    "part2string = mycorpus.raw('state_union_part2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1tokens = nltk.word_tokenize(part1string)\n",
    "\n",
    "\n",
    "part2tokens = nltk.word_tokenize(part2string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Complete',\n",
       " 'State',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Union',\n",
       " 'Addresses',\n",
       " ',',\n",
       " 'from',\n",
       " '1946',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Present',\n",
       " '(',\n",
       " '#',\n",
       " '41',\n",
       " 'in',\n",
       " 'our',\n",
       " 'series',\n",
       " 'of',\n",
       " 'US',\n",
       " 'Presidential',\n",
       " 'State',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Union',\n",
       " 'Addresses',\n",
       " ')',\n",
       " 'Copyright',\n",
       " 'laws',\n",
       " 'are',\n",
       " 'changing',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'Be',\n",
       " 'sure',\n",
       " 'to',\n",
       " 'check',\n",
       " 'the',\n",
       " 'copyright',\n",
       " 'laws',\n",
       " 'for',\n",
       " 'your',\n",
       " 'country',\n",
       " 'before',\n",
       " 'downloading',\n",
       " 'or',\n",
       " 'redistributing',\n",
       " 'this',\n",
       " 'or',\n",
       " 'any',\n",
       " 'other',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'eBook',\n",
       " '.',\n",
       " 'This',\n",
       " 'header',\n",
       " 'should',\n",
       " 'be',\n",
       " 'the',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'seen',\n",
       " 'when',\n",
       " 'viewing',\n",
       " 'this',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'file',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'not',\n",
       " 'remove',\n",
       " 'it',\n",
       " '.',\n",
       " 'Do',\n",
       " 'not',\n",
       " 'change',\n",
       " 'or',\n",
       " 'edit',\n",
       " 'the',\n",
       " 'header',\n",
       " 'without',\n",
       " 'written',\n",
       " 'permission',\n",
       " '.',\n",
       " 'Please',\n",
       " 'read',\n",
       " 'the',\n",
       " '``',\n",
       " 'legal']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1tokens[:100]\n",
    "part2tokens[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3137736\n",
      "2621720\n"
     ]
    }
   ],
   "source": [
    "print(len(part1string))\n",
    "\n",
    "print(len(part2string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557939\n",
      "484221\n"
     ]
    }
   ],
   "source": [
    "print(len(part1tokens))\n",
    "print(len(part2tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphapart1 = [w for w in part1tokens if w.isalpha()]\n",
    "alphapart2 = [w for w in part2tokens if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Complete',\n",
       " 'State',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Union',\n",
       " 'Addresses',\n",
       " 'from',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Present',\n",
       " 'in',\n",
       " 'our',\n",
       " 'series',\n",
       " 'of',\n",
       " 'US',\n",
       " 'Presidential',\n",
       " 'State',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Union',\n",
       " 'Addresses',\n",
       " 'Copyright',\n",
       " 'laws',\n",
       " 'are',\n",
       " 'changing',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'world',\n",
       " 'Be',\n",
       " 'sure',\n",
       " 'to',\n",
       " 'check',\n",
       " 'the',\n",
       " 'copyright',\n",
       " 'laws',\n",
       " 'for',\n",
       " 'your',\n",
       " 'country',\n",
       " 'before',\n",
       " 'downloading',\n",
       " 'or',\n",
       " 'redistributing',\n",
       " 'this',\n",
       " 'or',\n",
       " 'any',\n",
       " 'other',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'eBook',\n",
       " 'This',\n",
       " 'header',\n",
       " 'should',\n",
       " 'be',\n",
       " 'the',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'seen',\n",
       " 'when',\n",
       " 'viewing',\n",
       " 'this',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'file',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'not',\n",
       " 'remove',\n",
       " 'it',\n",
       " 'Do',\n",
       " 'not',\n",
       " 'change',\n",
       " 'or',\n",
       " 'edit',\n",
       " 'the',\n",
       " 'header',\n",
       " 'without',\n",
       " 'written',\n",
       " 'permission',\n",
       " 'Please',\n",
       " 'read',\n",
       " 'the',\n",
       " 'legal',\n",
       " 'small',\n",
       " 'print',\n",
       " 'and',\n",
       " 'other',\n",
       " 'information',\n",
       " 'about',\n",
       " 'the',\n",
       " 'eBook',\n",
       " 'and',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'at']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphapart1[:100]\n",
    "alphapart2[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphalowerpart1 = [w.lower( ) for w in alphapart1]\n",
    "alphalowerpart2 = [w.lower( ) for w in alphapart2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'of',\n",
       " 'complete',\n",
       " 'state',\n",
       " 'of',\n",
       " 'the',\n",
       " 'union',\n",
       " 'addresses',\n",
       " 'from',\n",
       " 'to',\n",
       " 'the',\n",
       " 'present',\n",
       " 'in',\n",
       " 'our',\n",
       " 'series',\n",
       " 'of',\n",
       " 'us',\n",
       " 'presidential',\n",
       " 'state',\n",
       " 'of',\n",
       " 'the',\n",
       " 'union',\n",
       " 'addresses',\n",
       " 'copyright',\n",
       " 'laws',\n",
       " 'are',\n",
       " 'changing',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'world',\n",
       " 'be',\n",
       " 'sure',\n",
       " 'to',\n",
       " 'check',\n",
       " 'the',\n",
       " 'copyright',\n",
       " 'laws',\n",
       " 'for',\n",
       " 'your',\n",
       " 'country',\n",
       " 'before',\n",
       " 'downloading',\n",
       " 'or',\n",
       " 'redistributing',\n",
       " 'this',\n",
       " 'or']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphalowerpart2[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "len(stopwords)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoppedalphalowerpart1 = [w for w in alphalowerpart1 if w not in stopwords]\n",
    "\n",
    "stoppedalphalowerpart2 = [w for w in alphalowerpart2 if w not in stopwords]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist0 = FreqDist(stoppedalphalowerpart1)\n",
    "fdist = FreqDist(stoppedalphalowerpart2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist0keys = list(fdist0.keys())\n",
    "\n",
    "\n",
    "fdistkeys = list(fdist.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenberg', 'ebook', 'complete', 'state', 'union', 'addresses', 'present', 'series', 'us', 'presidential', 'copyright', 'laws', 'changing', 'world', 'sure', 'check', 'country', 'downloading', 'redistributing', 'header', 'first', 'thing', 'seen', 'viewing', 'file', 'please', 'remove', 'change', 'edit', 'without', 'written', 'permission', 'read', 'legal', 'small', 'print', 'information', 'bottom', 'included', 'important', 'specific', 'rights', 'restrictions', 'may', 'used', 'also', 'find', 'make', 'donation']\n",
      "for second doc\n",
      "['project', 'gutenberg', 'ebook', 'complete', 'state', 'union', 'addresses', 'present', 'series', 'us', 'presidential', 'copyright', 'laws', 'changing', 'world', 'sure', 'check', 'country', 'downloading', 'redistributing', 'header', 'first', 'thing', 'seen', 'viewing', 'file', 'please', 'remove', 'change', 'edit', 'without', 'written', 'permission', 'read', 'legal', 'small', 'print', 'information', 'bottom', 'included', 'important', 'specific', 'rights', 'restrictions', 'may', 'used', 'also', 'find', 'make', 'donation']\n"
     ]
    }
   ],
   "source": [
    "print(fdist0keys[:50])\n",
    "\n",
    "print(\"for second doc\")\n",
    "print(fdistkeys[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "top0keys = fdist0.most_common(50)\n",
    "topkeys = fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('must', 1628)\n",
      "('people', 1506)\n",
      "('world', 1490)\n",
      "('new', 1441)\n",
      "('america', 1271)\n",
      "('year', 1265)\n",
      "('congress', 1230)\n",
      "('us', 1216)\n",
      "('government', 1111)\n",
      "('years', 1111)\n",
      "('american', 950)\n",
      "('nation', 861)\n",
      "('one', 804)\n",
      "('every', 780)\n",
      "('make', 778)\n",
      "('work', 754)\n",
      "('federal', 744)\n",
      "('time', 741)\n",
      "('americans', 688)\n",
      "('help', 686)\n",
      "('security', 685)\n",
      "('war', 674)\n",
      "('economic', 671)\n",
      "('peace', 668)\n",
      "('nations', 645)\n",
      "('also', 639)\n",
      "('program', 638)\n",
      "('country', 630)\n",
      "('national', 609)\n",
      "('economy', 588)\n",
      "('great', 583)\n",
      "('last', 572)\n",
      "('many', 563)\n",
      "('free', 558)\n",
      "('need', 554)\n",
      "('first', 553)\n",
      "('let', 549)\n",
      "('would', 548)\n",
      "('state', 520)\n",
      "('tax', 514)\n",
      "('know', 507)\n",
      "('million', 507)\n",
      "('freedom', 503)\n",
      "('budget', 501)\n",
      "('health', 489)\n",
      "('future', 475)\n",
      "('system', 463)\n",
      "('programs', 462)\n",
      "('tonight', 461)\n",
      "('union', 460)\n"
     ]
    }
   ],
   "source": [
    "for pair in topkeys:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('government', 2220)\n",
      "('may', 1562)\n",
      "('congress', 1500)\n",
      "('upon', 1455)\n",
      "('would', 1381)\n",
      "('public', 1375)\n",
      "('country', 1163)\n",
      "('great', 1073)\n",
      "('made', 1061)\n",
      "('state', 1045)\n",
      "('last', 911)\n",
      "('war', 834)\n",
      "('present', 812)\n",
      "('time', 808)\n",
      "('people', 786)\n",
      "('year', 785)\n",
      "('power', 744)\n",
      "('citizens', 723)\n",
      "('subject', 711)\n",
      "('shall', 694)\n",
      "('without', 663)\n",
      "('union', 643)\n",
      "('act', 627)\n",
      "('treaty', 624)\n",
      "('one', 620)\n",
      "('part', 618)\n",
      "('mexico', 605)\n",
      "('general', 601)\n",
      "('every', 590)\n",
      "('treasury', 590)\n",
      "('necessary', 575)\n",
      "('constitution', 557)\n",
      "('new', 548)\n",
      "('duty', 529)\n",
      "('foreign', 519)\n",
      "('two', 510)\n",
      "('commerce', 506)\n",
      "('nations', 502)\n",
      "('peace', 501)\n",
      "('system', 494)\n",
      "('laws', 492)\n",
      "('duties', 488)\n",
      "('within', 479)\n",
      "('law', 477)\n",
      "('us', 463)\n",
      "('interests', 451)\n",
      "('interest', 444)\n",
      "('amount', 443)\n",
      "('also', 438)\n",
      "('well', 433)\n"
     ]
    }
   ],
   "source": [
    "for pair in top0keys:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Freq Dist\n",
    "Another way to look for interesting characterizations of a corpus is to look at pairs of words that are frequently collocated, that is, they occur in a sequence called a bigram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We start by making an object called a BigramCollocationFinder.  The finder then allows us to call other functions to filter the bigrams that it collected and to give scores to the bigrams.  As a first step, we can score the bigrams by frequency.  Be sure to use the original tokens from the document and not the filtered tokens that you might create to look at word frequencies. For example, the bigrams of the sentence “run after the fox!”  include “run after”, “after the”, and “the fox”. If you use the original tokens you will obtain these bigrams. If you filter the sentence with the stop words list, then you may not have “the” after the filtering. Then your bigrams will have “after fox” – which is not a bigram in the original dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(alphalowerpart2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('of', 'the'), 0.007686567516636518)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scored)\n",
    "first = scored[0]\n",
    "type(first)\n",
    "first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the'), 0.007686567516636518)\n",
      "(('in', 'the'), 0.005889492899075722)\n",
      "(('to', 'the'), 0.0033414725149126493)\n",
      "(('of', 'our'), 0.003183254381697704)\n",
      "(('and', 'the'), 0.002555104778187623)\n",
      "(('for', 'the'), 0.0024063325036720777)\n",
      "(('we', 'have'), 0.00233076563407688)\n",
      "(('we', 'must'), 0.0021819933595613344)\n",
      "(('the', 'world'), 0.0019718230034996907)\n",
      "(('the', 'congress'), 0.0016813628484931495)\n",
      "(('will', 'be'), 0.001492445674505155)\n",
      "(('we', 'are'), 0.0014664695630818058)\n",
      "(('it', 'is'), 0.0014475778456830065)\n",
      "(('we', 'can'), 0.0014404934516584567)\n",
      "(('on', 'the'), 0.0014381319869836067)\n",
      "(('the', 'united'), 0.0013602036527135591)\n",
      "(('we', 'will'), 0.0013365890059650598)\n",
      "(('with', 'the'), 0.00132714314726566)\n",
      "(('and', 'to'), 0.001291721177142911)\n",
      "(('in', 'our'), 0.0012775523890938116)\n",
      "(('that', 'the'), 0.0012421304189710626)\n",
      "(('by', 'the'), 0.0012137928428728635)\n",
      "(('that', 'we'), 0.0011453103673022156)\n",
      "(('united', 'states'), 0.0010909966797806672)\n",
      "(('and', 'we'), 0.0010744664270567177)\n",
      "(('in', 'this'), 0.0010697434977070177)\n",
      "(('to', 'be'), 0.0010555747096579182)\n",
      "(('more', 'than'), 0.0009894536987621202)\n",
      "(('in', 'a'), 0.0009729234460381707)\n",
      "(('of', 'a'), 0.0009682005166884709)\n",
      "(('and', 'i'), 0.000965839052013621)\n",
      "(('has', 'been'), 0.0009587546579890711)\n",
      "(('is', 'the'), 0.0009138868291669224)\n",
      "(('have', 'been'), 0.0008997180411178229)\n",
      "(('of', 'this'), 0.0008855492530687233)\n",
      "(('the', 'american'), 0.000866657535669924)\n",
      "(('a', 'new'), 0.0008406814242465747)\n",
      "(('i', 'have'), 0.0008005365247741259)\n",
      "(('is', 'a'), 0.0007745604133507767)\n",
      "(('must', 'be'), 0.0007745604133507767)\n",
      "(('to', 'make'), 0.0007698374840010768)\n",
      "(('from', 'the'), 0.000762753089976527)\n",
      "(('as', 'a'), 0.0007462228372525775)\n",
      "(('to', 'help'), 0.0007462228372525775)\n",
      "(('state', 'of'), 0.0007414999079028777)\n",
      "(('at', 'the'), 0.0007202467258292283)\n",
      "(('the', 'people'), 0.0007155237964795285)\n",
      "(('can', 'not'), 0.0006801018263567796)\n",
      "(('if', 'we'), 0.0006801018263567796)\n",
      "(('to', 'our'), 0.0006801018263567796)\n"
     ]
    }
   ],
   "source": [
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying filters now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before that, adding the 'united', 'states' in the list of stop words, because these words will definitely occur frequently in this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.append(\"united\")\n",
    "stopwords.append(\"states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('american', 'people'), 0.000564390057289133)\n",
      "(('last', 'year'), 0.000531329551841234)\n",
      "(('fiscal', 'year'), 0.0004392324295220868)\n",
      "(('federal', 'government'), 0.00043450950017238693)\n",
      "(('social', 'security'), 0.00042742510614783715)\n",
      "(('health', 'care'), 0.00042034071212328737)\n",
      "(('let', 'us'), 0.00041089485342388763)\n",
      "(('years', 'ago'), 0.00038255727732568846)\n",
      "(('union', 'address'), 0.00032588212512929017)\n",
      "(('billion', 'dollars'), 0.00030699040773049074)\n",
      "(('million', 'dollars'), 0.00029990601370594096)\n",
      "(('soviet', 'union'), 0.0002951830843562411)\n",
      "(('free', 'world'), 0.0002550381848837923)\n",
      "(('every', 'american'), 0.00023378500281014296)\n",
      "(('economic', 'growth'), 0.0002219776794358933)\n",
      "(('middle', 'east'), 0.00021489328541134353)\n",
      "(('make', 'sure'), 0.00020780889138679375)\n",
      "(('free', 'nations'), 0.00019836303268739404)\n",
      "(('first', 'time'), 0.00019127863866284423)\n",
      "(('four', 'years'), 0.00019127863866284423)\n",
      "(('armed', 'forces'), 0.00017710985061374467)\n",
      "(('must', 'continue'), 0.00017474838593889474)\n",
      "(('world', 'war'), 0.00017474838593889474)\n",
      "(('work', 'together'), 0.0001700254565891949)\n",
      "(('foreign', 'policy'), 0.00016530252723949502)\n",
      "(('new', 'jobs'), 0.00016530252723949502)\n",
      "(('two', 'years'), 0.00015821813321494524)\n",
      "(('vice', 'president'), 0.00015821813321494524)\n",
      "(('next', 'years'), 0.0001558566685400953)\n",
      "(('national', 'security'), 0.0001464108098406956)\n",
      "(('must', 'also'), 0.00014404934516584566)\n",
      "(('address', 'january'), 0.00014168788049099575)\n",
      "(('human', 'rights'), 0.0001393264158161458)\n",
      "(('health', 'insurance'), 0.00013696495114129588)\n",
      "(('fellow', 'americans'), 0.00013224202179159603)\n",
      "(('fellow', 'citizens'), 0.00013224202179159603)\n",
      "(('past', 'year'), 0.00013224202179159603)\n",
      "(('civil', 'rights'), 0.00012751909244189616)\n",
      "(('young', 'people'), 0.00012751909244189616)\n",
      "(('past', 'years'), 0.0001227961630921963)\n",
      "(('private', 'sector'), 0.0001227961630921963)\n",
      "(('god', 'bless'), 0.00012043469841734637)\n",
      "(('local', 'governments'), 0.00012043469841734637)\n",
      "(('nuclear', 'weapons'), 0.00012043469841734637)\n",
      "(('interest', 'rates'), 0.00011571176906764651)\n",
      "(('next', 'year'), 0.00011571176906764651)\n",
      "(('balanced', 'budget'), 0.00011335030439279659)\n",
      "(('must', 'make'), 0.00011335030439279659)\n",
      "(('high', 'school'), 0.00011098883971794665)\n",
      "(('minimum', 'wage'), 0.00011098883971794665)\n"
     ]
    }
   ],
   "source": [
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def apply_ngram_filter(self, fn):\n",
    "        # \"Removes candidate ngrams (w1, w2, ...) where fn(w1, w2, ...) evaluates to True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('american', 'people'), 0.000564390057289133)\n",
      "(('last', 'year'), 0.000531329551841234)\n",
      "(('fiscal', 'year'), 0.0004392324295220868)\n",
      "(('federal', 'government'), 0.00043450950017238693)\n",
      "(('social', 'security'), 0.00042742510614783715)\n",
      "(('health', 'care'), 0.00042034071212328737)\n",
      "(('years', 'ago'), 0.00038255727732568846)\n",
      "(('union', 'address'), 0.00032588212512929017)\n",
      "(('billion', 'dollars'), 0.00030699040773049074)\n",
      "(('million', 'dollars'), 0.00029990601370594096)\n",
      "(('soviet', 'union'), 0.0002951830843562411)\n",
      "(('free', 'world'), 0.0002550381848837923)\n",
      "(('every', 'american'), 0.00023378500281014296)\n",
      "(('economic', 'growth'), 0.0002219776794358933)\n",
      "(('middle', 'east'), 0.00021489328541134353)\n",
      "(('make', 'sure'), 0.00020780889138679375)\n",
      "(('free', 'nations'), 0.00019836303268739404)\n",
      "(('first', 'time'), 0.00019127863866284423)\n",
      "(('four', 'years'), 0.00019127863866284423)\n",
      "(('armed', 'forces'), 0.00017710985061374467)\n",
      "(('must', 'continue'), 0.00017474838593889474)\n",
      "(('world', 'war'), 0.00017474838593889474)\n",
      "(('work', 'together'), 0.0001700254565891949)\n",
      "(('foreign', 'policy'), 0.00016530252723949502)\n",
      "(('vice', 'president'), 0.00015821813321494524)\n",
      "(('next', 'years'), 0.0001558566685400953)\n",
      "(('national', 'security'), 0.0001464108098406956)\n",
      "(('must', 'also'), 0.00014404934516584566)\n",
      "(('address', 'january'), 0.00014168788049099575)\n",
      "(('human', 'rights'), 0.0001393264158161458)\n",
      "(('health', 'insurance'), 0.00013696495114129588)\n",
      "(('fellow', 'americans'), 0.00013224202179159603)\n",
      "(('fellow', 'citizens'), 0.00013224202179159603)\n",
      "(('past', 'year'), 0.00013224202179159603)\n",
      "(('civil', 'rights'), 0.00012751909244189616)\n",
      "(('young', 'people'), 0.00012751909244189616)\n",
      "(('past', 'years'), 0.0001227961630921963)\n",
      "(('private', 'sector'), 0.0001227961630921963)\n",
      "(('local', 'governments'), 0.00012043469841734637)\n",
      "(('nuclear', 'weapons'), 0.00012043469841734637)\n",
      "(('interest', 'rates'), 0.00011571176906764651)\n",
      "(('next', 'year'), 0.00011571176906764651)\n",
      "(('balanced', 'budget'), 0.00011335030439279659)\n",
      "(('must', 'make'), 0.00011335030439279659)\n",
      "(('high', 'school'), 0.00011098883971794665)\n",
      "(('minimum', 'wage'), 0.00011098883971794665)\n",
      "(('white', 'house'), 0.00010862737504309673)\n",
      "(('cold', 'war'), 0.00010154298101854694)\n",
      "(('middle', 'class'), 0.00010154298101854694)\n",
      "(('last', 'years'), 9.918151634369702e-05)\n"
     ]
    }
   ],
   "source": [
    "finder.apply_ngram_filter(lambda w1, w2: len(w1) < 4)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information and other scores\n",
    "Recall that Mutual Information is a score introduced in the paper by Church and Hanks, where they defined it as an Association Ratio. Note that technically the original information theoretic definition of mutual information allows the two words to be in either order, but that the association ratio defined by Church and Hanks requires the words to be in order from left to right wherever they appear in the window\n",
    "\n",
    "In NLTK, the mutual information score is given by a function for Pointwise Mutual Information, where this is the version without the window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder2 = BigramCollocationFinder.from_words(stoppedalphalowerpart2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder2.apply_freq_filter(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('el', 'salvador'), 15.164265341881517)\n",
      "(('ladies', 'gentlemen'), 15.164265341881517)\n",
      "(('bin', 'laden'), 14.94187292054507)\n",
      "(('saudi', 'arabia'), 14.94187292054507)\n",
      "(('sam', 'rayburn'), 14.749227842602672)\n",
      "(('jimmy', 'carter'), 14.42729974771531)\n",
      "(('endowed', 'creator'), 14.316268435326567)\n",
      "(('northern', 'ireland'), 14.164265341881517)\n",
      "(('gerald', 'ford'), 14.097151146022979)\n",
      "(('floor', 'appears'), 14.012262248436468)\n",
      "(('iron', 'curtain'), 13.94187292054507)\n",
      "(('grass', 'roots'), 13.901230936047725)\n",
      "(('thomas', 'jefferson'), 13.785753718627788)\n",
      "(('sons', 'daughters'), 13.749227842602675)\n",
      "(('red', 'tape'), 13.749227842602673)\n",
      "(('jill', 'biden'), 13.678838514711277)\n",
      "(('lyndon', 'johnson'), 13.661765001352334)\n",
      "(('barack', 'obama'), 13.66176500135233)\n",
      "(('teen', 'pregnancy'), 13.57930284116036)\n",
      "(('abraham', 'lincoln'), 13.49183999991002)\n",
      "(('mom', 'dad'), 13.456446093374828)\n",
      "(('empowerment', 'zones'), 13.356910419823912)\n",
      "(('william', 'clinton'), 13.327764074164396)\n",
      "(('ronald', 'reagan'), 13.289796223965373)\n",
      "(('synthetic', 'fuels'), 13.275296654270264)\n",
      "(('greece', 'turkey'), 13.204907326378866)\n",
      "(('elementary', 'secondary'), 13.122788705905355)\n",
      "(('intercontinental', 'ballistic'), 13.003273465209212)\n",
      "(('feeding', 'hungry'), 12.967868129078013)\n",
      "(('river', 'basins'), 12.8912468474751)\n",
      "(('status', 'quo'), 12.891246847475099)\n",
      "(('commander', 'chief'), 12.856143046519184)\n",
      "(('prime', 'minister'), 12.842337246994152)\n",
      "(('nationwide', 'radio'), 12.801695262496807)\n",
      "(('reported', 'floor'), 12.764334734992882)\n",
      "(('radio', 'television'), 12.749227842602675)\n",
      "(('introduced', 'thomas'), 12.670276501207852)\n",
      "(('project', 'gutenberg'), 12.661765001352334)\n",
      "(('dwight', 'eisenhower'), 12.643433178580077)\n",
      "(('al', 'qaeda'), 12.619944825657706)\n",
      "(('al', 'qaida'), 12.619944825657704)\n",
      "(('richard', 'nixon'), 12.602871312298765)\n",
      "(('saddam', 'hussein'), 12.57930284116036)\n",
      "(('harry', 'truman'), 12.539774476973722)\n",
      "(('supreme', 'court'), 12.525226168404565)\n",
      "(('carbon', 'pollution'), 12.469119923409936)\n",
      "(('baby', 'boom'), 12.463825623740426)\n",
      "(('persian', 'gulf'), 12.437169991739372)\n",
      "(('capitol', 'introduced'), 12.396711427881888)\n",
      "(('sides', 'aisle'), 12.356910419823912)\n"
     ]
    }
   ],
   "source": [
    "scored = finder2.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
